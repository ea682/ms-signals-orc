server:
  port: ${PORT:4108}

rest-client:
  timeout:
    connect-ms: 2000
    read-ms: 5000
  metric-wallet:
    info-base: ${URL_METRIC:http://192.168.1.123:4102}
  binance-service:
    info-base: ${URL_BINANCE:http://192.168.1.123:4106}

logging:
  pattern:
    console: '%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(%-5level) %clr([%t]){faint} %clr(%logger{36}){cyan} : %msg%n%wex'

spring:
  kafka:
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      properties:
        spring.json.add.type.headers: false
    bootstrap-servers: ${KAFKA_BROKERS:192.168.1.123:9094}
    consumer:
      group-id: operaciones-consumer
  output:
    ansi:
      enabled: ALWAYS

  datasource:
    url: jdbc:postgresql://192.168.1.123:5432/trading_futuros?currentSchema=futuros_operaciones
    username: ${DB_USER:postgres}
    password: ${DB_PASSWORD:5450940}

  jpa:
    show-sql: false
    hibernate:
      ddl-auto: validate
      naming:
        physical-strategy: org.hibernate.boot.model.naming.CamelCaseToUnderscoresNamingStrategy
    properties:
      hibernate:
        default_schema: ${DB_SCHEMA:futuros_operaciones}
        jdbc.time_zone: UTC
        format_sql: true
management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus

app:
  kafka:
    operaciones:
      topic: ${KAFKA_TOPIC_OPERACIONES:operaciones-eventos}

binance:
  dispatch:
    delay-ms: 100
    pool-size: 4

copy:
  job:
    worker:
      pool-size: 16
      max-batch: 200
      poll-ms: 200
      max-attempts: 12

engine:
  copy:
    execution-job-worker:
      enabled: true